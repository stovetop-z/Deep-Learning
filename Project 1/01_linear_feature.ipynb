{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "\n",
    "# Exploring and Manipulating Linear Classifier Templates\n",
    "\n",
    "This project will teach you how to create a linear classifier using visual templates. You will:\n",
    "\n",
    "1. **Load and preprocess a combined weights image** containing all 10 weights (0-9)\n",
    "2. **Convert the image into a weight matrix** for a linear classifier\n",
    "3. **Test the classifier on MNIST dataset** and achieve >20% accuracy\n",
    "\n",
    "\n",
    "**Important**: \n",
    "You need to provide your own combined weights image named <span style=\"color: red;\">all_weights_combined_(YOUR CUID).png</span> in the Project 1 folder. \n",
    "This image should contain all 10 weight templates stacked vertically, with each template being approximately 28x28 pixels when resized.\n",
    "\n",
    "**Weight template Generator**:\n",
    "You can use this temporary website to generate and download your image:  \n",
    "[https://nianyi-li.github.io/CPSC-6430-fall25/P1_GUI/](https://nianyi-li.github.io/CPSC-6430-fall25/P1_GUI/)\n",
    "\n",
    "After downloading, rename your file as instructed, <span style=\"color: red;\">all_weights_combined_(YOUR CUID).png</span>, and place it in the Project 1 folder.\n",
    "\n",
    "***NOTE:***\n",
    "When filling in the code, please REMOVE the `pass` statement.\n",
    "DO NOT remove the TODO coding highlight in your submission.\n",
    "\n",
    "\n",
    "### <span style=\"color: red;\"> Grading Criteria:</span>\n",
    "\n",
    "- Test accuracy must be >20% (60% points)\n",
    "- Code quality and implementation (8% points)\n",
    "- Analysis and answers to questions (32% points)\n",
    "- **Total: 5 points (50% of project score)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Google Colab Setup (Comment out for local computer running)\n",
    "################################################################################\n",
    "# Uncomment and set the path to your project folder in Google Drive\n",
    "################################################################################\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# FOLDERNAME = 'cpsc8430/assignments/project1/'\n",
    "# assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "# # Now that we've mounted your Drive, this ensures that\n",
    "# # the Python interpreter of the Colab VM can load\n",
    "# # python files from within it.\n",
    "\n",
    "# import sys\n",
    "# sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
    "# %cd /content/drive/My\\ Drive/$FOLDERNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the combined digits image\n",
    "image_path = 'all_weights_combined.png' # all_digits_combined_4\n",
    "img = Image.open(image_path)\n",
    "img_array = np.array(img)\n",
    "\n",
    "# Convert to grayscale if image is RGB, White is 255, Black is 0\n",
    "if len(img_array.shape) == 3:\n",
    "    img_array = img_array.mean(axis=2)\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# TODO: Try different eta values to control the grayscale inversion of the image.\n",
    "# eta = 0.0 -> original image, eta = 1.0 -> fully inverted (255 - img_array), eta = 0.5 -> halfway\n",
    "\n",
    "eta = 1  # Change this value between 0.0 and 1.0 to experiment\n",
    "img_modified = (1 - eta) * img_array + eta * (255 - img_array)\n",
    "################################################################################\n",
    "\n",
    "# Resize to height 280 and width 28 (10 blocks of 28x28 stacked vertically)\n",
    "target_size = (28, 280)  # Note: PIL uses (width, height)\n",
    "img_resized = Image.fromarray(img_modified.astype(np.uint8)).resize(target_size)\n",
    "img_tensor = torch.tensor(np.array(img_resized), dtype=torch.float32)\n",
    "\n",
    "# Normalize to [-1, 1]\n",
    "img_min = img_tensor.min()\n",
    "img_max = img_tensor.max()\n",
    "img_normalized = 2.0 * (img_tensor - img_min) / (img_max - img_min) - 1.0\n",
    "\n",
    "# Display original, modified, and resized images\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img_array, cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(img_modified, cmap='gray')\n",
    "plt.title('Modified Image (After Eta Adjustment)')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(img_normalized.numpy(), cmap='gray')\n",
    "plt.title('Resized and Normalized Image (280x28)')\n",
    "plt.tight_layout()\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Normalized image tensor shape: {img_normalized.shape}\")\n",
    "print(f\"Value range: [{img_normalized.min():.2f}, {img_normalized.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create weight matrix [10, 784] from the normalized image\n",
    "weight_matrix = torch.zeros(10, 784)\n",
    "\n",
    "# The image is 280x28, which means we have 10 blocks of 28x28 stacked vertically\n",
    "for i in range(10):\n",
    "    # Extract the i-th 28x28 block (vertically stacked)\n",
    "    start_row = i * 28\n",
    "    end_row = start_row + 28\n",
    "    block = img_normalized[start_row:end_row, :]\n",
    "    \n",
    "    # Flatten the block and assign to the corresponding row in weight matrix\n",
    "    weight_matrix[i] = block.flatten()\n",
    "\n",
    "# Visualize each weight as a 28x28 image\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(weight_matrix[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'Weight {i}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Weight matrix shape: {weight_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the large weight matrix [10, 784]\n",
    "plt.figure(figsize=(20, 3))\n",
    "\n",
    "# Create a heatmap of the entire weight matrix\n",
    "plt.subplot(1, 2, 1)\n",
    "weight_heatmap = plt.imshow(weight_matrix.numpy(), cmap='RdBu_r', aspect='auto')\n",
    "plt.colorbar(weight_heatmap, label='Weight Value')\n",
    "plt.title('Weight Matrix Heatmap [10, 784]')\n",
    "plt.xlabel('Input Features (784)')\n",
    "plt.ylabel('Output Classes (10)')\n",
    "\n",
    "\n",
    "print(\"Weight matrix visualization complete!\")\n",
    "print(f\"Matrix statistics:\")\n",
    "print(f\"  Min value: {weight_matrix.min():.3f}\")\n",
    "print(f\"  Max value: {weight_matrix.max():.3f}\")\n",
    "print(f\"  Mean value: {weight_matrix.mean():.3f}\")\n",
    "print(f\"  Std value: {weight_matrix.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_accuracy_cell",
    "test": "test_accuracy"
   },
   "outputs": [],
   "source": [
    "# Load MNIST test dataset\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.1307,), (0.3081,))  # MNIST mean and std\n",
    "])\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='cpsc8430/datasets/MNIST',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1000,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Create random bias\n",
    "bias = torch.randn(10)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            # Flatten the images\n",
    "            images = images.view(-1, 784)\n",
    "            \n",
    "            # Forward pass: compute scores\n",
    "            scores = torch.mm(images, weight_matrix.t()) + bias\n",
    "            \n",
    "            # Get predictions\n",
    "            _, predicted = torch.max(scores, 1)\n",
    "            \n",
    "            # Update statistics\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return 100 * correct / total\n",
    "\n",
    "# Test the classifier\n",
    "accuracy = evaluate()\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# IMPORTANT: This accuracy should be greater than 20% for full credit\n",
    "# assert accuracy > 20.0, f\"Test accuracy {accuracy:.2f}% is below the required threshold of 20%\"\n",
    "# print(f\"âœ… Test accuracy {accuracy:.2f}% meets the requirement of >20%!\")\n",
    "\n",
    "# Store the result for grading\n",
    "test_accuracy_result = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "## Inline Questions\n",
    "\n",
    "### Question 1\n",
    "Try adjusting the value of `eta` (located in the second code cell after \"TODO\") to each of the following values: {0, 0.25, 0.5, 0.75, 1}. For each value, run the code and report the resulting test accuracy. What do you observe as you change `eta`? Why do you think this happens?\n",
    "\n",
    "$\\color{blue}{\\textit{Your Answer:}}$\n",
    "\n",
    "- Testing accuracy for $\\eta=0$:\n",
    "- Testing accuracy for $\\eta=0.25$:\n",
    "- Testing accuracy for $\\eta=0.5$:\n",
    "- Testing accuracy for $\\eta=0.75$:\n",
    "- Testing accuracy for $\\eta=1$:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Question 2\n",
    "Why do you think this approach achieves an accuracy above 20%? What are the advantages and limitations of using visual templates as weights?\n",
    "\n",
    "$\\color{blue}{\t\\textit{Your Answer:}}$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Question 3\n",
    "How could you improve the performance of this classifier? What modifications would you make to achieve higher accuracy?\n",
    "\n",
    "$\\color{blue}{\t\\textit{Your Answer:}}$\n",
    "\n",
    "\n",
    "### Question 4\n",
    "What does the weight matrix represent in this linear classifier? How does it relate to the original combined digits image?\n",
    "\n",
    "$\\color{blue}{\t\\textit{Your Answer:}}$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
